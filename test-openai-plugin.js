/**
 * OpenAI Plugin æ”¹é€ æµ‹è¯•æ–‡ä»¶
 *
 * è¿™ä¸ªæ–‡ä»¶åŒ…å«äº†æµ‹è¯• iFlow API å…¼å®¹æ€§å’Œæ”¹é€ åçš„ OpenAI æ’ä»¶çš„å„ç§æµ‹è¯•
 * ä½¿ç”¨æ–¹æ³•ï¼šnode test-openai-plugin.js
 */

// æµ‹è¯•é…ç½®
const CONFIG = {
  API_KEY: "sk-989ec1d533419b87f484a9eb13166203",
  BASE_URL: "https://apis.iflow.cn/v1",
  MODEL: "qwen3-coder-plus",  // æ›´æ–°ä¸ºå®é™…ä½¿ç”¨çš„æ¨¡å‹
  SMALL_MODEL: "qwen3-coder-plus",
  LARGE_MODEL: "qwen3-coder-plus"
};

/**
 * æµ‹è¯• 1: ç›´æ¥ fetch è°ƒç”¨ iFlow API
 * éªŒè¯ iFlow API çš„åŸºæœ¬å…¼å®¹æ€§
 */
async function testDirectFetch() {
  console.log("\n=== æµ‹è¯• 1: ç›´æ¥ fetch è°ƒç”¨ iFlow API ===");

  try {
    console.log("æµ‹è¯•ç›´æ¥ fetch åˆ° /v1/chat/completions...");

    const response = await fetch(`${CONFIG.BASE_URL}/chat/completions`, {
      method: "POST",
      headers: {
        "Authorization": `Bearer ${CONFIG.API_KEY}`,
        "Content-Type": "application/json"
      },
      body: JSON.stringify({
        model: CONFIG.MODEL,
        messages: [
          { role: "user", content: "ä½ å¥½ï¼Œè¯·ç®€å•ä»‹ç»ä¸€ä¸‹è‡ªå·±" }
        ],
        temperature: 0.7,
        max_tokens: 1000
      })
    });

    console.log("å“åº”çŠ¶æ€:", response.status);

    if (!response.ok) {
      const errorText = await response.text();
      console.error("é”™è¯¯å“åº”:", errorText);
      throw new Error(`HTTP ${response.status}: ${errorText}`);
    }

    const data = await response.json();
    console.log("âœ… ç›´æ¥ fetch æµ‹è¯•æˆåŠŸï¼");

    if (data.choices && data.choices[0]) {
      console.log("ç”Ÿæˆæ–‡æœ¬:", data.choices[0].message.content);
    }

    if (data.usage) {
      console.log("Token ä½¿ç”¨:", data.usage);
    }

  } catch (error) {
    console.error("âŒ ç›´æ¥ fetch æµ‹è¯•å¤±è´¥:", error.message);
  }
}

/**
 * æµ‹è¯• 2: @ai-sdk/openai å…¼å®¹æ€§æµ‹è¯•
 * éªŒè¯åŸå§‹çš„ @ai-sdk/openai åº“æ˜¯å¦èƒ½æ­£å¸¸å·¥ä½œ
 */
async function testAISDK() {
  console.log("\n=== æµ‹è¯• 2: @ai-sdk/openai å…¼å®¹æ€§æµ‹è¯• ===");

  try {
    const { createOpenAI } = await import("@ai-sdk/openai");

    const client = createOpenAI({
      apiKey: CONFIG.API_KEY,
      baseURL: CONFIG.BASE_URL
    });

    const model = client.languageModel(CONFIG.MODEL);

    console.log("æµ‹è¯• @ai-sdk/openai æ–‡æœ¬ç”Ÿæˆ...");

    const response = await model.doGenerate({
      inputFormat: "prompt",
      prompt: "ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ"
    });

    console.log("âœ… @ai-sdk/openai æµ‹è¯•æˆåŠŸï¼");
    console.log("ç”Ÿæˆæ–‡æœ¬:", response.text);

    if (response.usage) {
      console.log("Token ä½¿ç”¨:", response.usage);
    }

  } catch (error) {
    console.error("âŒ @ai-sdk/openai æµ‹è¯•å¤±è´¥:", error.message);
    console.log("è¿™å¯èƒ½æ˜¯ç”±äº /v1/responses ç«¯ç‚¹ä¸å­˜åœ¨å¯¼è‡´çš„");
  }
}

/**
 * æµ‹è¯• 3: æ”¹é€ åçš„æ’ä»¶æµ‹è¯•
 * æµ‹è¯•ä¿®æ”¹åçš„ ElizaOS OpenAI æ’ä»¶
 */
async function testModifiedPlugin() {
  console.log("\n=== æµ‹è¯• 3: æ”¹é€ åçš„æ’ä»¶æµ‹è¯• ===");

  try {
    const { fileURLToPath } = await import('url');
    const { dirname, join } = await import('path');
    const { createRequire } = await import('module');

    const __filename = fileURLToPath(import.meta.url);
    const __dirname = dirname(__filename);
    const require = createRequire(import.meta.url);

    // æµ‹è¯• ESM ç‰ˆæœ¬
    const esmPluginPath = join(__dirname, 'node_modules/@elizaos/plugin-openai/dist/node/index.node.js');
    const openaiPlugin = require(esmPluginPath).default;

    console.log("æ’ä»¶åç§°:", openaiPlugin.name);
    console.log("å¯ç”¨æ¨¡å‹:", Object.keys(openaiPlugin.models));

    // æ¨¡æ‹Ÿ runtime å¯¹è±¡
    const mockRuntime = {
      getSetting: (key) => {
        const settings = {
          OPENAI_API_KEY: CONFIG.API_KEY,
          OPENAI_BASE_URL: CONFIG.BASE_URL,
          OPENAI_SMALL_MODEL: CONFIG.SMALL_MODEL,
          OPENAI_LARGE_MODEL: CONFIG.LARGE_MODEL
        };
        return settings[key];
      },
      character: {
        system: "You are a helpful AI assistant."
      },
      emitEvent: (event, data) => {
        console.log(`äº‹ä»¶è§¦å‘: ${event}`, data ? "âœ…" : "");
      }
    };

    // æµ‹è¯•åˆå§‹åŒ–
    if (openaiPlugin.init) {
      openaiPlugin.init({}, mockRuntime);
      console.log("âœ… æ’ä»¶åˆå§‹åŒ–æˆåŠŸ");
    }

    // æµ‹è¯• TEXT_SMALL æ¨¡å‹
    if (openaiPlugin.models.TEXT_SMALL) {
      console.log("\næµ‹è¯• TEXT_SMALL æ¨¡å‹...");
      const result = await openaiPlugin.models.TEXT_SMALL(mockRuntime, {
        prompt: "ç®€å•è§£é‡Šä¸€ä¸‹ä»€ä¹ˆæ˜¯åŒºå—é“¾",
        maxTokens: 100,
        temperature: 0.7
      });
      console.log("âœ… TEXT_SMALL ç»“æœ:", result);
    }

    // æµ‹è¯• TEXT_LARGE æ¨¡å‹
    if (openaiPlugin.models.TEXT_LARGE) {
      console.log("\næµ‹è¯• TEXT_LARGE æ¨¡å‹...");
      const result = await openaiPlugin.models.TEXT_LARGE(mockRuntime, {
        prompt: "è¯¦ç»†è§£é‡Šé‡å­è®¡ç®—çš„åŸç†",
        maxTokens: 150,
        temperature: 0.7
      });
      console.log("âœ… TEXT_LARGE ç»“æœ:", result);
    }

  } catch (error) {
    console.error("âŒ æ’ä»¶æµ‹è¯•å¤±è´¥:", error.message);
  }
}

/**
 * ä¸»æµ‹è¯•å‡½æ•°
 */
async function runAllTests() {
  console.log("ğŸš€ å¼€å§‹ OpenAI Plugin æ”¹é€ æµ‹è¯•");
  console.log("=====================================");

  await testDirectFetch();
  await testAISDK();
  await testModifiedPlugin();

  console.log("\n=====================================");
  console.log("ğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆï¼");
  console.log("\nğŸ“ æµ‹è¯•è¯´æ˜:");
  console.log("1. å¦‚æœç›´æ¥ fetch æˆåŠŸä½† @ai-sdk/openai å¤±è´¥ï¼Œè¯´æ˜éœ€è¦æ”¹é€ æ’ä»¶");
  console.log("2. å¦‚æœæ”¹é€ åçš„æ’ä»¶æµ‹è¯•æˆåŠŸï¼Œè¯´æ˜æ”¹é€ å®Œæˆ");
  console.log("3. å»ºè®®åœ¨æ”¹é€ æ’ä»¶åè¿è¡Œæ­¤æµ‹è¯•éªŒè¯åŠŸèƒ½");
}

// è¿è¡Œæµ‹è¯•
runAllTests().catch(console.error);